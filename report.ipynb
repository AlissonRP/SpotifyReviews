{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Um Breve Ensaio Sobre os Sentimentos...\"\n",
        "subtitle:  Dos Reviews do Spotify\n",
        "author: \"Alisson Rosa\"\n",
        "format: \n",
        "  pdf:\n",
        "    include-in-header: \n",
        "      text: |\n",
        "        \\usepackage{float}\n",
        "        \\usepackage{graphicx}\n",
        "    number-sections: true\n",
        "    fig-width: 5.9\n",
        "    fig-height: 2.5\n",
        "    fig-pos: H\n",
        "    indent: 2m\n",
        "    geometry:\n",
        "      - top=20mm\n",
        "      - left=18mm\n",
        "      - right=18mm\n",
        "      - heightrounded\n",
        "execute:\n",
        "  warning: false\n",
        "  echo: false\n",
        "lang: pt\n",
        "bibliography: docs/bib.bib\n",
        "nocite: |\n",
        "          @*\n",
        "---"
      ],
      "id": "4a1f15a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\section{\\centering Introdução}\n",
        "\n",
        "O Spotify é um serviço digital que dá acesso instantâneo a milhões de músicas, podcasts, vídeos e outros conteúdos de criadores no mundo todo. Pode ser acessado pelo *browser*, sendo possível também baixar o aplicativo, estando disponível para diversas plataformas digitais. \n",
        "Nesse ensaio, vamos analisar os *reviews* feitos na Play Store sobre a versão para *Android*, dessa maneira vamos examinar o comportamento dos reviews (estrelas), junto com o texto deixado pelo autor do mesmo.\n",
        "\n",
        "\n",
        "\\subsection{Uma visão Geral das Avaliações}\n",
        "\n",
        "Como é de conhecimento geral, erros geram muito mais comentários que acertos^[Se você não dispõe de tal conhecimento, essa análise é a evidência pura e concentra disso.], dessa maneira, reclamações de problemas tendem a criar mais agitações que congratulações de acertos, nesse sentido, espera-se uma quantidade considerável de avaliações nota 1 do aplicativo. Pois os usuários de aplicativos são propensos a ter expectativas de sua utilização, entretanto, expectativas não satisfeitas, geram frustrações, e uma maneira de destilar tamanha frustração é lançar toda a fúria no *review* na Play Store. Começamos, portanto, avaliando pela @fig-prop, a proporção das avaliações.\n"
      ],
      "id": "6b848aba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from utils.utils import time_plot, total_variable, my_wc, Display\n",
        "prm={\"figure.figsize\":(9, 3),\n",
        "'figure.dpi':150}\n",
        "plt.rcParams.update(prm)\n",
        "sns.set_palette(\"viridis\")\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "id": "14076873",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(\"data/reviews.csv\")"
      ],
      "id": "a22f42db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-prop\n",
        "#| fig-cap: Proporção das Avaliações por Estrelas\n",
        "grouped_data = df.groupby(\"Rating\", as_index=False).size()\n",
        "grouped_data = grouped_data.assign(Proporcao=grouped_data[\"size\"] / grouped_data[\"size\"].sum())\n",
        "sns.barplot(data= grouped_data, x=\"Rating\", y=\"Proporcao\")\n",
        "plt.xlabel(\"Avaliação\")\n",
        "plt.ylabel(\"Proporção\");\n"
      ],
      "id": "fig-prop",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notamos assim uma disputa entre amor e ódio em relação ao aplicativo, portanto agora é importante refletir sobre alguns pontos:\n",
        "\n",
        "* Existe algum padrão no uso de palavras para esses *reviews*? \n",
        "* Há algum momento no tempo que há mais *reviews* \"negativos\" que \"positivos\"? \n",
        "* É possível classificar o sentimento do autor somente baseado no texto?\n",
        "\n",
        "\n",
        "Nas seguintes seções vamos aprofundar a análise desses *reviews* em relação ao tempo,  também aprofundaremos ainda mais a análise em relação aos *reviews* considerando também o texto deixado pelo autor, dessa maneira, as respostas para essas perguntas vão surgir ao longo do texto.\n",
        "\n",
        "\\subsection{Analisando os Review de Maneira Temporal}\n"
      ],
      "id": "aed91181"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['Time_submitted'] = pd.to_datetime(df['Time_submitted'])\n",
        "\n",
        "#%%\n",
        "df['month'] = df['Time_submitted'].apply(lambda x: x.month)\n",
        "df['hour'] = df['Time_submitted'].apply(lambda x: x.hour)\n",
        "df['day'] = df['Time_submitted'].apply(lambda x: x.day)"
      ],
      "id": "b6d7fce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos nessa subseção averiguar os *review* em termos de contagens e valores médios referentes, a mês, dia e hora.\n",
        "\n",
        "\\subsubsection{Review Ao longo dos Meses}\n",
        "\n",
        "O que pode se notar pela @fig-plt é um comportamento elevado de *reviews* no mês 4 e o que acarretou em um decréscimo no valor médio dos *reviews* no mesmo mês. \n"
      ],
      "id": "5a28da9a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plt\n",
        "#| fig-cap: Comportamento dos Reviews ao longo dos meses\n",
        "time_plot(df, 'month')"
      ],
      "id": "fig-plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsubsection{Review Ao longo dos Dias}\n",
        "Em relação aos dias temos um comportamento semelhantes aos meses, em que dias que possuem mais *reviews*, possuem avaliação média inferior aos demais, isso indica portanto que o ódio nasce quando as pessoas se reúnem^[Ou é ao contrário?]."
      ],
      "id": "7f5337b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Comportamento dos Reviews ao longo dos dias\"\n",
        "\n",
        "time_plot(df, 'day')"
      ],
      "id": "1aae0998",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsubsection{Review Ao longo das Horas}\n",
        "\n",
        "Em relação as horas temos uma grande quantidade de *reviews* no horário das 10-15h e depois o pico acontece as 18h, assim como o menor valor de *review* também acontece as 18h. Vale ressaltar que a média em relação as horas tende a manter-se estacionária até as 15h, um comportamento não visto na média dos meses e dias."
      ],
      "id": "33cc9a7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Comportamento dos Reviews ao longo das horas\"\n",
        "\n",
        "time_plot(df, 'hour')"
      ],
      "id": "53132dad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\section{\\centering Texto  e seus ajustes}\n",
        "\n",
        "Em toda análise textual é necessária um bom pré processamento dos dados, portanto é isso que vamos tratar nessa seção. Realizaremos:\n",
        "\n",
        "* Remoção de Stop Words^[Stop Words são palavras as quais possuem uma alta taxa de frequência no texto, mas carregam pouca informações para a análise a ser realizada.]\n",
        "\n",
        "* Lematização^[Tarefa de determinar se duas palavras tem a mesma raiz, apesar de diferença de \"estrutura\"]\n",
        "\n",
        "* Remoção de Espaços indevidos\n",
        "\n",
        "Porém antes do processamento, vejamos o comportamento da frequência das palavras:\n",
        "Para o casos de 5 estrelas notamos palavras positivas como \"love\", \"great\"  e \"easy\" em destaque.\n"
      ],
      "id": "b75e76a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-pos: 'h'\n",
        "#| fig-cap: \"Wordcloud para Reviews de 5 estrelas\"\n",
        "my_wc(df, 4)"
      ],
      "id": "3445dab7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E para o caso de reviews de 1 estrela nota-se palavras referentes a problemas como \"fix\", \"even\" e \"issue\".\n"
      ],
      "id": "438ac1a8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-pos: 'h'\n",
        "#| fig-cap: \"Wordcloud para Reviews de 1 estrela\"\n",
        "my_wc(df, 'podre')"
      ],
      "id": "72af70b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nota-se em ambos os casos que palavras como \"Spotify\", \"song\", \"app\" e \"music\" possuem uma alta frequência de exibição, entretanto não agregam muita informação para a análise, assim é interessante a remoção delas.\n",
        "\n",
        "\\subsubsection{Um ajuste dos Reviews}\n",
        "Vamos aqui nessa subseção recategorizar a variável numérica da avaliação deixando da seguinte maneira:\n",
        "\n",
        "* 1 a 2 Estrelas: Negativo\n",
        "* 3 Estrelas: Neutro\n",
        "* 4 a 5 Estrelas: Positivo\n",
        "\n",
        "Portanto a partir desse momento, quando refere-se a review negativos, estamos nos referenciando a 1 a 2 estrelas e assim por diante.\n"
      ],
      "id": "1ef9529d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['Review_words'] = [len(x.split()) for x in df['Review']]\n",
        "rating = df['Rating'] \n",
        "df['Sentiment'] = np.where((1 <= rating) & (rating <= 2), 'negativo', \n",
        "np.where((4 <=rating) & (rating<=5), 'positivo', 'neutral'))"
      ],
      "id": "5ea12852",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsection{Análise Sem as Stop Words}\n",
        "\n",
        "Nessa breve subseção remover as **stops words**, fazer algumas análises em relação aos *reviews* agora categorizados e também refazer algumas análises da seção anterior. Além das stop words \"tradicionais\" do inglês, serão removidas as seguintes palavras: app, song, music, e spotify.\n"
      ],
      "id": "3b0c5bc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stop_words.update([\"app\", \"song\", \"Spotify\", \"music\", \"spotify\"])\n",
        "\n",
        "df['Review_wsw'] = df['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))"
      ],
      "id": "3e952edc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vejamos a titulo de curiosidade a wordcloud para *reviews* de 5 estrelas, agora sem stop words.\n"
      ],
      "id": "894761aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Wordcloud para Reviews de 5 estrelas sem Stop Words\"\n",
        "my_wc(df, var = \"Review_wsw\", Filter = 4)"
      ],
      "id": "3075f501",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nota-se, agora um destaque para palavras positivas como: \"love\", \"great\" e \"good\".\n",
        "\n",
        "\n",
        "## Palavras em Review\n",
        "Nessa subseção vamos averiguar a quantidade de palavras pelos *reviews*, será que *reviews* positivos possuem mais palavras que negativos? Será que o comportamento da quantidade das palavras se mantém constante ao longo do tempo? As respostas para essas perguntas e mais serão respondidas nessa seção.\n",
        "\n",
        "### Para Reviews Negativos\n",
        "Para o caso de *reviews* negativos, notamos uma média de aproximadamente 38 palavras, um mínimo de 3 palavras, e um *review* que incrivelmente atinge 700 palavras!\n",
        "\n",
        "Vale que salientar que apesar da existência de reviews bastante tagarelas, a quantidade de palavras tende a se comportar a sua maior parte até 100, como podemos ver tanto pela @tbl-neg e pela @fig-neg."
      ],
      "id": "c131a2d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-neg\n",
        "#| tbl-cap: Análise descritiva para a quantidade de palavras em sentimentos negativos\n",
        "Display(df[df['Sentiment'] == 'negativo'][['Review_words']].rename(columns={\"Review_words\": \"Total de Palavras\"}).describe().T.to_markdown())"
      ],
      "id": "tbl-neg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-neg\n",
        "#| fig-cap: Quantidade de palavras para sentimentos negativos\n",
        "sns.boxplot(data=df[df[\"Sentiment\"] == 'negativo'], x=\"Review_words\")\n",
        "plt.xlabel(\"Quantidade de Palavras\");\n"
      ],
      "id": "fig-neg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Para Reviews Positivos\n",
        "Referente aos *reviews* positivos temos um hábito bastante diferente do que os negativos, pois  temos o quantil de 75% de somente 31 palavras, enquanto no negativo eram 50, a mediana é de 18 para casos positivos enquanto para negativos era de 32. Pela @fig-pos podemos reparar muitos *reviews* categorizados como *outliers* isso se deve ao fato de que a maior parte possui poucas palavras.\n"
      ],
      "id": "a477c079"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-pos\n",
        "#| tbl-cap: Análise descritiva para a quantidade de palavras em sentimentos positivos\n",
        "Display(df[df['Sentiment'] == 'positivo'][['Review_words']].rename(columns={\"Review_words\": \"Total de Palavras\"}).describe().T.to_markdown())"
      ],
      "id": "tbl-pos",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-pos\n",
        "#| fig-cap: Quantidade de palavras para sentimentos positivos\n",
        "sns.boxplot(data=df[df[\"Sentiment\"] == 'positivo'], x=\"Review_words\")\n",
        "plt.xlabel(\"Quantidade de Palavras\");"
      ],
      "id": "fig-pos",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Revisitando o tempo\n",
        "Vamos nessa subseção averiguar o comportamento da quantidade de palavras por sentimento ao longo do tempo. Assim o que podemos notar pela @fig-tmp é que os *reviews* classificados como positivos tem uma quantidade de palavras bem inferior aos negativos não somente no sentido global como visto pela @tbl-neg e @tbl-pos mas também no sentido temporal.\n",
        "\n",
        "Em relação ao comportamento em relação aos dias, tem-se que para os *reviews* positivos visualmente uma estacionariedade em relação a quantidade de palavras, o que não acontece para o caso de *reviews* neutros e negativos. Para o caso dos meses é visível a não estacionariedade, tem-se que para meses iniciais do ano, os *reviews* possuem mais palavras que os situados no meses centrais do ano.\n"
      ],
      "id": "617bf6e6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-height": "2.9"
      },
      "source": [
        "#| label: fig-tmp\n",
        "\n",
        "#| fig-cap: \"(a) Total de Palavras por Review ao longo dos dias, (b) Total de Palavras por Review ao longo dos meses\"\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].set_title(\"(a)\")\n",
        "ax[0].set_ylabel(\"Total\")\n",
        "ax[1].set_ylabel(\"Total\")\n",
        "ax[1].set_title(\"(b)\")\n",
        "sns.lineplot(data=df[df['Review_words']< 180], y='Review_words', x='day', hue='Sentiment', ax=ax[0])\n",
        "ax[0].get_legend().remove()\n",
        "sns.lineplot(data=df[df['Review_words']< 180], y='Review_words', x='month', hue='Sentiment', ax=ax[1])\n",
        "fig.show()"
      ],
      "id": "fig-tmp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\section{\\centering Modelagem}\n",
        "Vamos nessa seção criar um modelo preditivo que fornece o sentimento do autor do *review* baseado no texto deixado pelo mesmo. Reiterando que um sentimento positivo nesse contexto, significa *review* numérico de 4 a 5 estrelas, e um sentimento negativo *reviews* de 1 a 2 estrelas na Play Store.\n"
      ],
      "id": "dd464d51"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = df[df['Sentiment'] != 'neutral']\n",
        "## MODELAGEM\n",
        "X = data['Review_wsw']\n",
        "y = data['Sentiment']"
      ],
      "id": "65331ded",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsection{Desenvolvendo as Covariáveis}\n",
        "Como vimos, não temos covariáveis \"automáticas\" no **dataset**, assim faz-se necessário a criação baseando-se no *review* escrito, vamos aqui utilizar de duas técnicas, a saber Vetores  de Contagens^[Count Vectorization] e TF-IDF. Dessa forma pretendemos avaliar o sentimento do usuário ao fazer o *review* escrito, por questões técnicas^[Técnicas aqui quer dizer: Não foi apresentado no curso a qual esse trabalho esta sendo apresentado] vamos utilizar somente os *reviews* que são positivos e negativos, dessa maneira removendo os classificados como neutros, tornando-se um problema de classificação binária.\n",
        "Vejamos pela @fig-pie a proporção de *reviews* agora categorizados como negativos e positivos.\n"
      ],
      "id": "e7204698"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-pie\n",
        "#| fig-cap: Proporção das Avaliações por Sentimento\n",
        "#| fig-pos: H\n",
        "plt.pie(x=y.value_counts(), labels=y.unique(), autopct='%.0f%%');"
      ],
      "id": "fig-pie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para a tristeza daqueles que tendem a inclinar-se a suspeitar mais do mal que do bem, temos agora uma quantidade levemente superior para casos de *reviews* de sentimentos positivos, dessa forma em termos de modelagem, é dito um problema de classes^[Onde classes refere-se : Positivo e Negativo] balanceadas.\n",
        "\n",
        "\n",
        "\\subsubsection{Count Vectorization}\n",
        "A ideia é bastante simples, vamos criar uma coluna/vetor para cada palavra única no banco de dados e associar a quantidade de vezes que aparece no *review* escrito, um exemplo didático pode ser visto a seguir.\n",
        "\n",
        "![Exemplo de CV](docs/imgs/vector.jpg){fig-align=\"center\"}\n"
      ],
      "id": "c1c759f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
      ],
      "id": "63c163b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vectorizer.fit(X_train)\n",
        "X_train_count = vectorizer.transform(X_train)\n",
        "X_test_count = vectorizer.transform(X_test)"
      ],
      "id": "e2b1851e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsubsection{TF-IDF}\n",
        "\n",
        "O termo TF-IDF significa \"Term Frequency - Inverse Document Frequency\", é uma técnica assim como Count Vectorizer (CV) para contar a quantidade de palavras em um documento^[Documento no contexto de NLP signfica observação], ao contrário do CV, aqui utilizamos *scores* para cada palavra, que, em geral, refere-se a relevância dela no documento.\n",
        "\n",
        "O método para computar o TF-IDF é feito multiplicando duas métricas:\n",
        "\n",
        "* Quantas vezes a palavra apareceu no documento (tf)\n",
        "* Inverso da frequência da palavra entre os documentos (idf)\n",
        "\n",
        "Em termos formais temos:\n",
        "Seja w uma palavra, d um documento, e D o conjunto dos documentos^[Também conhecido como corpus], o tf-idf fica definido como:\n",
        "\n",
        "$$tfidf(w, d, D) = tf(w, d)idf(t, D)$$"
      ],
      "id": "3c195e0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
        "tfidf.fit(X_train)\n",
        "X_train_tfidf = tfidf.transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "id": "1897c964",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsection{Ajustando Modelos}\n",
        "Vamos aqui ajustar uma regressão logística e um modelo de random forest para classificar o sentimento do texto. Desse modo vamos ajustar 4 modelos, pois vamos ajustar também um modelo para CV e um modelo para TF-IDF\n",
        "\n",
        "\n",
        "\\subsubsection{Modelos Com CV}\n",
        "Pela @fig-models somos capazes de constatar que apesar de CV ser um método ingênuo, ele é capaz de criar covariáveis que conseguem predizer com uma acurácia extremamente adequada nos dados de teste o sentimento do autor do *review* em ambos os modelos.\n"
      ],
      "id": "6d1860e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf_cv = RandomForestClassifier(random_state=19, n_estimators=105, min_samples_split=12, min_samples_leaf=1)\n",
        "rf_cv.fit(X_train_count, y_train)\n",
        "rf_cv_accuracy = rf_cv.score(X_test_count, y_test)"
      ],
      "id": "4e883bcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rl_cv = LogisticRegression(random_state=0, penalty='none', max_iter=10000)\n",
        "rl_cv.fit(X_train_count, y_train)\n",
        "rl_cv_score = rl_cv.score(X_test_count, y_test)"
      ],
      "id": "6ab9629b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-models\n",
        "\n",
        "#| fig-cap: \"(a) Curva Roc para a Random Forest usando CV, (b)  Curva Roc para a \n",
        "# Regressão Logistica usando CV\"\n",
        "fig, ax = plt.subplots(1,2)\n",
        "ax[0].set_title(\"(a)\")\n",
        "ax[1].set_title(\"(b)\")\n",
        "RocCurveDisplay.from_estimator(rf_cv, X_test_count, y_test, ax=ax[0])\n",
        "RocCurveDisplay.from_estimator(rl_cv, X_test_count, y_test, ax=ax[1]);"
      ],
      "id": "fig-models",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsubsection{Modelos Com TF-IDF}\n",
        "\n",
        "Apesar da técnica TF-IDF ser mais meticulosa que o CV, o seu esforço em criar covariáveis não condiz com a sua performance na detecção dos sentimentos, visto que em ambos os modelos, tem desempenho inferior aos modelos com CV.^[A realidade pode ser dolorosa, mas é algo que você deve aprender a aceitar.]\n"
      ],
      "id": "ccb21c3f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf_tf = RandomForestClassifier()\n",
        "rf_tf.fit(X_train_tfidf, y_train)\n",
        "rf_tf_score = rf_tf.score(X_test_tfidf, y_test)"
      ],
      "id": "2189a3e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rl_tf = LogisticRegression(random_state=0, penalty='none', max_iter=10000)\n",
        "rl_tf.fit(X_train_tfidf, y_train)\n",
        "rl_tf_score = rl_tf.score(X_test_tfidf, y_test)"
      ],
      "id": "6775f5e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-models-tf\n",
        "\n",
        "#| fig-cap: \"(a) Curva Roc para a Random Forest usando CV, (b)  Curva Roc para a Regressão Logistica usando CV\"\n",
        "fig, ax = plt.subplots(1,2)\n",
        "ax[0].set_title(\"(a)\")\n",
        "ax[1].set_title(\"(b)\")\n",
        "RocCurveDisplay.from_estimator(rf_tf, X_test_tfidf, y_test, ax=ax[0])\n",
        "RocCurveDisplay.from_estimator(rl_tf, X_test_tfidf, y_test, ax=ax[1]);"
      ],
      "id": "fig-models-tf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\subsubsection{Modelo Final}\n",
        "Finalizando, temos como modelo final uma random forest com pré processamento de CV, com 25% das observações sendo para teste, obteve aproximadamente uma acurácia de 88%.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# O começo e o fim são um só\n",
        "\n",
        "\n",
        "Um fato a ser considerado é que a existência do *review* escrito é dependente do review numérico, assim a análise anterior somente teria validade, se por algum motivo fosse possível deixar somente o review escrito, o que no momento não acontece.\n",
        "\n",
        "Assim, é necessário extrair o sentimento do autor do texto **exclusivamente** pelo texto, pois dessa maneira podemos conflitar a predição do sentimento com relação a estrela deixada como *review*. Visto que existe um fenômeno tal qual o *review*  numérico não condiz com o sentimento do autor, pois como já dizia Dostoievski \"A natureza das pessoas não são todas iguais; para muitas, uma conclusão lógica transforma-se às vezes num sentimento fortíssimo que domina todo o seu ser e que é muito difícil de expulsar ou transformar...\".\n",
        "\n",
        "\n",
        "# Epilógo\n",
        "\n",
        "Vamos aqui introduzir um modelo mais robusto para analisar os sentimentos, vamos conflitar a classificação com o review numérico, e juntamente comparar com as predições do modelo anteriormente utilizado.\n",
        "\n",
        "## Modelo Vader\n",
        "\n",
        "Valence Aware Dictionary for Sentiment Reasoning, ou Vader é um modelo de classificação de sentimentos semi-supervisionado onde é possível analisar ambas^[Positivo e Negativo] polaridades de um texto, Vader é capaz de fornecer não somente o sentimento, mas também a intensidade do mesmo.\n",
        "\n",
        "O modelo possui uma grande vantagem sobre os que foram utilizados aqui, pois não é necessário pré-processamento do texto e ele também consegue lidar bem com pontuações, emojis e palavras em caixa baixa/alta.\n",
        "\n",
        "O Vader nos fornece a intensidade de sentimento positivo, negativo, neutro e também um escore denominado *compound* que normaliza^[A medida fica entre -1 e 1] os três sentimentos anteriores em um só, sendo valores mais próximos de -1 indicando sentimento negativo e mais próximos de 1 sentimentos positivos.\n",
        "\n",
        "\n",
        "Vejamos dessa maneira pela  @tbl-vad a comparação da Random com CV e do Vader."
      ],
      "id": "d874090d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def my_predict(text):\n",
        "    teste = vectorizer.transform(pd.Series(text))\n",
        "    return rf_cv.predict(teste)\n",
        "#%%\n",
        "def predict_vader(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    sentiment = sid.polarity_scores(text)\n",
        "    return sentiment['compound']\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "predict_vader(X_test.reset_index(drop=True)[3])\n",
        "\n",
        "#%%\n",
        "my_predict(X_test.reset_index(drop=True)[3])[0]\n",
        "\n",
        "#%%\n",
        "\n",
        "texts = [X_test.reset_index(drop=True)[3],\n",
        "X_test.reset_index(drop=True)[21],\n",
        "X_test.reset_index(drop=True)[35],\n",
        "X_test.reset_index(drop=True)[40],\n",
        "X_test.reset_index(drop=True)[47]]\n",
        "\n",
        "#%%\n",
        "compar_models = pd.DataFrame({\"texts\": texts})\n",
        "\n",
        "\n",
        "#%%\n",
        "compar_models['Random Forest'] = compar_models.apply(my_predict)\n",
        "\n",
        "compar_models['Vader'] = compar_models['texts'].apply(predict_vader)\n",
        "#%%\n",
        "\n",
        "compar_models[\"Vader Resumido\"] = compar_models[\"Vader\"].apply(lambda x: np.where(x > 0, 'positivo',\n",
        "np.where(x < 0, 'negativo', 'neutro')))\n",
        "\n",
        "# %%\n",
        "real_values = [y_test.reset_index(drop=True)[3],\n",
        "y_test.reset_index(drop=True)[21],\n",
        "y_test.reset_index(drop=True)[35],\n",
        "y_test.reset_index(drop=True)[40],\n",
        "y_test.reset_index(drop=True)[47]]\n",
        "\n",
        "compar_models[\"Sentimento Real\"] = real_values"
      ],
      "id": "77641a95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-vad\n",
        "#| tbl-cap: Comparação dos Modelos\n",
        "Display(compar_models.drop('Vader', axis=1).to_markdown())"
      ],
      "id": "tbl-vad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O que podemos notar é que em casos que o Vader classifica o *review* como neutro (*compound* = 0) a random forest classifica como negativo, e no ocorrências em que o Vader não classifica como neutro temos concordância entre os modelos.\n",
        "\n",
        "# Referências\n"
      ],
      "id": "9b5694ef"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}